{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[piezo]: https://en.wikipedia.org/wiki/Piezoelectric_sensor\n",
    "[LTS5]: https://lts5www.epfl.ch/\n",
    "[antenna arrays]: https://en.wikipedia.org/wiki/Phased_array\n",
    "[DAS]: https://www.semanticscholar.org/paper/Coherent-array-imaging-using-phased-subarrays.-Part-Johnson-Karaman/f2f05db5d4ad3635e8744381df45cacfb97453b0/figure/0\n",
    "[Tanter and Fink]: https://ieeexplore.ieee.org/ielx7/58/6689765/06689779.pdf?tp=&arnumber=6689779&isnumber=6689765&ref=aHR0cHM6Ly93d3cuZ29vZ2xlLmNoLw==\n",
    "[directivity]: https://en.wikipedia.org/wiki/Directivity\n",
    "[Ronneberger et al.]: https://arxiv.org/abs/1505.04597\n",
    "[Perdios et al.]: https://ieeexplore.ieee.org/abstract/document/8580183\n",
    "[residual]: https://ieeexplore.ieee.org/ielx7/42/8124116/07947200.pdf?tp=&arnumber=7947200&isnumber=8124116&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2Fic3RyYWN0L2RvY3VtZW50Lzc5NDcyMDA=\n",
    "[Montaldo et al.]: https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4816058\n",
    "\n",
    "## Introduction\n",
    "In our research at [LTS5][LTS5] we analyse using deep learning for the purpose\n",
    "of medical ultrasound (US) image reconstruction with a strong emphasize on \n",
    "convolutional neural networks (NNs). In this hands-on session we will share \n",
    "some of our insights and results, while also discussing some very important and \n",
    "hopefully useful general basics in deep learning.\n",
    "\n",
    "In the next few paragraphs we provide you with some context about ultrasound\n",
    "image reconstruction and our reasoning why we think deep learning might be very \n",
    "useful for US image reconstruction. Ultrasound experts and deep learning\n",
    "purists can easily skip all paragraphs of the introduction except for the last\n",
    "one, where we describe the task of the hands-on session.  \n",
    "\n",
    "### Ultrasound basics\n",
    "\n",
    "US imaging is a widely used medical imaging modality, which is relatively \n",
    "cheap, highly-flexible (potentially portable) and usually non-invasive. \n",
    "Additionally, in strong contrast to other widely used medical imaging \n",
    "modalities such as MRI and CT, it is real-time capable.\n",
    "\n",
    "To reconstruct a US image, pulse-echo measurements are conducted where \n",
    "US waves are transmitted into the tissue of interest and the reflections due to  \n",
    "local acoustic impedance inhomogeneities(声阻抗不均匀性) are measured. The time of flight\n",
    "between sending a wave and receiving its echo provides information about\n",
    "the positions of the reflector and the intensity of the reflection gives\n",
    "information about the reflectors density.\n",
    "\n",
    "For transmitting and receiving waves, US probes (transceiver) are used, which \n",
    "consists of an array of [piezoelectric][piezo] transducer elements, that allow \n",
    "to generate pressure waves (sound) from electrical signals, as well as the \n",
    "reciprocal process. Arrays of piezoelectric(压电) elements are used for beamforming, \n",
    "i.e. to focus on specific points inside the tissue and to steer the waves along \n",
    "different angles, analogous to [antenna arrays][antenna arrays]. Amongst the \n",
    "most widely used US probe types are the linear array, the convex array and the \n",
    "phased array.\n",
    "\n",
    "![](figures/transducers.jpg)\n",
    "\n",
    "Traditionally, a focused-wave scheme is used to sample the full region of \n",
    "interest (ROI), which means that the ROI is split into sub-regions and\n",
    "for each a focused pulse-echo measurement is conducted.\n",
    "\n",
    "![](figures/conventional_trans.png)![](figures/conventional_rec.png)\n",
    "\n",
    "After $N$ pulse-echo measurements (one for each sub-region) we end up with $N$ \n",
    "voltage vs. time series at each transducer element. To reconstruct an image \n",
    "from the measurement data usually the [delay-and-sum][DAS] (DAS) method is \n",
    "used, which reconstructs each single point of the image by first shifting each \n",
    "elements voltage vs. time series in time (delay) by an amount corresponding to \n",
    "the physical distance between said element and the point inside the tissue. \n",
    "Then the shifted time series of each transducer element are summed to get \n",
    "the value of the image point. In the example US image below a convex array was \n",
    "used, which is why the image has the famous conic shape. \n",
    "\n",
    "![](figures/echographybaby.jpg)\n",
    "  \n",
    "### Ultrafast ultrasound imaging\n",
    "\n",
    "In ultrafast US imaging ([Tanter and Fink][Tanter and Fink]) an \n",
    "unfocused plane or diverging wave (PW/DW) is sent into the tissue, which \n",
    "thereby insonifies the entire ROI at once. The reflections coming from all \n",
    "over the ROI are measured simultaneously using the transducer elements and are \n",
    "then combined using the delay-and-sum (DAS) method to form a full US image from \n",
    "a single pulse-echo measurement.\n",
    "\n",
    "![](figures/ultrafast_trans.png)![](figures/ultrafast_rec.png)\n",
    " \n",
    "Thus, compared to conventional imaging, where many pulse-echo measurements have \n",
    "to be conducted to reconstruct an image, only a single measurement is necessary \n",
    "to form a full US image. This has the potential to drastically increase the \n",
    "achieved frame-rate (remember: US imaging is real-time), the time \n",
    "resolution (potentially highly accurate velocity measurements) and lower the \n",
    "energy consumption drastically. Entirely new imaging modes have been unlocked \n",
    "by this new approach, such as:\n",
    " \n",
    " - Shear wave elastography\n",
    " - Functional US imaging\n",
    " - High-sensitivity vector-flow imaging\n",
    "\n",
    "Unfortunately, mainly because of the fact that overall a much smaller amount \n",
    "of energy is used to insonify the tissue, an image reconstructed from a \n",
    "single ultrafast US measurement is usually of rather low quality (LQ). Below \n",
    "we show some simulated LQ example images reconstructed using single PW \n",
    "ultrafast imaging compared to their high-quality (HQ) counterparts. \n",
    " \n",
    " ![](figures/lq_examples.png)\n",
    " \n",
    "Most typical artifacts found in US images are strongly related to the \n",
    "[directivity][directivity] of the used probe array, thus:\n",
    " \n",
    " - Higher side lobes -> lower contrast\n",
    " - Broader main lobe -> lower resolution\n",
    " - Potential grating lobe (~array sampling) -> devastates entire image regions\n",
    "  - Ghost artifact -> Can lead to misinterpretations\n",
    " \n",
    "One image feature that may be viewed as an image artifact are the \n",
    "intensity fluctuations called \"speckle\", which are very current\n",
    "in ultrasound images. However, different to noise, speckle actually contains\n",
    "significant information about sub-resolution particles and thus can be used\n",
    "for post-processing, such as blood flow measurement. Therefor, it is \n",
    "interesting for image reconstruction methods to preserve this pattern.\n",
    " \n",
    "### From LQ to HQ image\n",
    "\n",
    "There are several methods to augment the quality of the LQ images obtained\n",
    "by ultrafast US imaging. The state-of-the-art method is called coherent\n",
    "compounding ([Montaldo et al.][Montaldo et al.]), where, instead of a single \n",
    "one, several pulse-echo measurements are conducted. The PWs of the different \n",
    "pulse-echo measurements are steered at a different angle (using array \n",
    "properties) to lower the side-lobe influence. The resulting images are summed \n",
    "coherently. Using a sufficient amount of PWs (usually >30) results in high \n",
    "quality images. \n",
    "\n",
    "While the number of transmission used in coherent compounding is significantly \n",
    "lower than in conventional US imaging, it still sacrifices high\n",
    "frame-rate for image quality. This works against the original strength of \n",
    "ultrafast US imaging. So, clearly, it would be interesting to find\n",
    "a method of augmenting image quality without having to have a large number of \n",
    "transmissions.\n",
    "\n",
    "### About Deep learning\n",
    "\n",
    "When should we use it? The first question one should aks himself is do\n",
    "I really need a deep learning, i.e. is there no state-of-the-art method that \n",
    "can provide what I want? Because of the \"black-box\" nature of deep learning it \n",
    "comes with a huge need for validation and testing, that is generally more\n",
    "demanding than using more classical alternatives. Secondly, using deep learning\n",
    "always comes with the need of a large, high-quality dataset, which is often\n",
    "not simple or even impossible to acquire.\n",
    "\n",
    "In biomedical imaging this is probably even more difficult than in other \n",
    "application areas of deep learning. A proper dataset means that in does not \n",
    "only have to be large (generally the more samples the better), it also needs to \n",
    "be of good quality. This means that the samples in the dataset must have a high \n",
    "diversity, such that they properly represent the distribution of all possible \n",
    "samples.\n",
    "\n",
    "A first approach here would be to have an in-vivo dataset, i.e. real\n",
    "US data gather from patients. This comes with the need for the proper \n",
    "equipment, a large number of voluntary participants and trained personal\n",
    "that have the time to acquire thousands of images. It is imperative to have a \n",
    "lot of different patients, to achieve high diversity in the dataset. \n",
    "\n",
    "Secondly, one could think about an in-vitro dataset, i.e. a dataset constructed\n",
    "by imaging phantoms in the laboratory. This comes with an even higher\n",
    "need for equipement (various phantoms), but does not need any participants.\n",
    "Again achieving a high diversity is quite hard, because to do so a plethora of \n",
    "different in-vitro phantoms must be used for data generation.\n",
    "\n",
    "The last approach would be to simulate the data. The huge advantage here is \n",
    "that, if a proper simulator is at hand one can generate an amount of images \n",
    "that  is only limited by the available time. Additionally, both equipment \n",
    "requirements and working hours can be kept minimal. Achieving high\n",
    "diversity in simulated data can easily be achieved by introducing randomness\n",
    "in the generated images. However, one has to be extra-careful when using \n",
    "simulated data in deep learning  and needs to constantly test the performance \n",
    "of trained networks on in-vivo and in-vitro test data, to be sure no errors are \n",
    "introduced because of simulation.\n",
    "\n",
    "### Task description\n",
    "\n",
    "To summarize we saw that using ultrafast US imaging we can obtain a LQ\n",
    "US image from a single pulse-echo measurement. Unfortunately, the images\n",
    "are of rather poor quality. While methods exist to augment the image quality of \n",
    "ultrafast US images, they always compromise on one of the key strengths of it, \n",
    "e.g. its high frame-rate in the case of coherent compounding. Obviously, we'd \n",
    "love to find a method with which we can augment the achieved image quality \n",
    "without having to do additional measurements. \n",
    "\n",
    "In this session we will use deep learning, specifically a convolutional NN, \n",
    "to augment the quality of said LQ images, obtained by ultrafast US imaging. \n",
    "For training we purely rely on simulated US images, generated using an in-house \n",
    "simulator. The input to our network are the LQ images. As reference (label) \n",
    "images we use HQ images obtained from synthetic aperture (SA) beamforming, \n",
    "which is an extreme variant of the earlier described coherent compounding \n",
    "method.\n",
    "\n",
    "The network architecture ([Perdios et al.]) we will use is a variant of the \n",
    "famous U-Net ([Ronneberger et al.][Ronneberger et al.]), adapted for image \n",
    "reconstruction.\n",
    "\n",
    " ![](figures/res_unet.png)\n",
    " \n",
    "At this point we want to emphasize on two main differences of our architecture\n",
    "and the conventional U-Net. The first difference is that we use \"same\" padding\n",
    "in all convolutional layers instead of \"valid\" padding. The reason for this is \n",
    "simple. While in segmentation (original use of the U-Net) it may be feasible \n",
    "to only analyze the center part of the image, it is not feasible for image \n",
    "reconstruction, since a large part (the border) of the network input image \n",
    "would be lost.\n",
    " \n",
    "The second significant difference is the use of a residual connection, which \n",
    "consists in adding the input image to the output of the last convolutional \n",
    "layer inside the network. This way, our network tries to learn only the \n",
    "difference between the input and the reference (label) image. This is a very\n",
    "useful technique for cases where network input and output are inherently \n",
    "similar (e.g. denoising tasks). Residual connections are a well-known tool that \n",
    "augment learning performance of NNS (e.g. [Hu Chen et al.][residual]). \n",
    "They can, however, only be applied if the input and output of the network have \n",
    "the same dimensions.\n",
    " \n",
    "Now, you should know everything you have to know to start some real hands-on. \n",
    "\n",
    "Enjoy!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data exploration awaits you in the [next notebook][next].\n",
    "\n",
    "[next]: dlssus_data_exploration.ipynb\n",
    "\n",
    "Or you can go back to the [outline].\n",
    "\n",
    "[outline]: dlssus_main.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
